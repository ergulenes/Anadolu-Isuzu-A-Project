# -*- coding: utf-8 -*-
"""Ai Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZmSsvdy9IKVxW--mlcSAvJGViBEQGzGW

##KÜTÜPHANELER
"""

# Commented out IPython magic to ensure Python compatibility.
import glob
import numpy as np
import pandas as pd
import cv2
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense, Flatten
from keras.callbacks import ModelCheckpoint
from matplotlib import pyplot as plt
# %matplotlib inline

"""## RESİM ÖN İŞLEME"""

image = []
for img in glob.glob("/content/drive/MyDrive/Anadolu Isuzu/İTHAL PARÇA/GÖRÜNTÜLER/*.jpeg"):
    img1= cv2.imread(img) #verileri cv2 ile okuyoruz
    res_image = cv2.resize(img1,(500,500),cv2.INTER_AREA) #verilerin pixellerini resize ediyoruz
    image.append(res_image) #verileri oluşturduğumuz image listesine ekliyoruz

res_image = np.array(image) #image listesini array'e dönüştürüyoruz
res_image = res_image[::-1]
res_image.shape

"""##TABLO VERİ ÖN İŞLEME"""

data = pd.read_excel("/content/drive/MyDrive/Anadolu Isuzu/İTHAL PARÇA/Kopya İthal Parça.xlsx")#excel dosyasını pandas ile okuyup data olarak tanımlıyorum
data_array = np.array(data) #pandas datamı array'e çeviriyorum.
data_array.shape

le = preprocessing.LabelEncoder()
data_array_fit = le.fit_transform(data_array) #Verilerimi sayısallaştırıyorum
data_array_categorical = tf.keras.utils.to_categorical((data_array_fit)) #verileri 0-1 haline getiriyorum

x_train, x_test, y_train, y_test = train_test_split(res_image,data_array_categorical, test_size=0.33)

# RESİM VE ENCODE KONTROL
a=9
print(y_train[a])

from PIL import Image
import numpy as np

img = Image.fromarray(x_train[a], 'RGB')
img.save('my.png')
img.show()

"""##VGG16"""

vgg = VGG16(input_shape=(500,500,3),
    include_top=False,
    weights='imagenet',
)

for layer in vgg.layers:
    layer.trainable = False


x = Flatten()(vgg.output)
dense_layer = Dense(5,activation="softmax")(x)

model = Model(vgg.input,dense_layer)

"""##COMPILE"""

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

"""##FIT"""

model.fit(x_train,y_train,
          batch_size=40,
          epochs = 20,
          validation_data=(x_test,y_test))

"""##PREDICT"""

predict_image = []

img1= cv2.imread("/content/drive/MyDrive/Anadolu Isuzu/İTHAL PARÇA/GÖRÜNTÜLER/IMG_1449 Büyük.jpeg") #verileri cv2 ile okuyoruz
res__predict_image = cv2.resize(img1,(500,500),cv2.INTER_AREA) #verilerin pixellerini resize ediyoruz
if not len(predict_image) == 0:
  predict_image.clear()
predict_image.append(res__predict_image) #verileri oluşturduğumuz image listesine ekliyoruz


predict_image = np.array(predict_image)

"""##RESULT"""

results = model.predict(
    predict_image,
    batch_size=None,
    verbose='auto',
    steps=None,
    callbacks=None,
    max_queue_size=10,
    workers=1,
    use_multiprocessing=False
)

"""##NAMES"""

class_names = [
    "PARCA ADI: VALF, ROLE KMP. (9730110040)            PARCA NO: 377779071051       LOKASYON: ITC08A",
    "PARCA ADI: SENSOR, KITAS +2, 33,8MM (217120002)    PARCA NO: 384331941051       LOKASYON: ITB09B",
    "PARCA ADI: SENSOR, KITAS 4.0 (2185.2000090003)     PARCA NO: 384404382151       LOKASYON: ITB04B",
    "PARCA ADI: VALF, ABS MODULATOR (4721950550)        PARCA NO: 387043655051       LOKASYON: ITC01A",
    "PARCA ADI: BUSCHJOST 2 YOLLU MOTORLU VANA          PARCA NO: 387466257051       LOKASYON: ITB12A",
              ]




print("Sınıflandırma sonucu:", class_names[np.argmax(results)])

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with open("model.tflite", 'wb') as f:
  f.write(tflite_model)